{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import RandomCutForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Role: arn:aws:iam::287758680514:role/service-role/AmazonSageMaker-ExecutionRole-20231027T004238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-1-287758680514'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aws_role = get_execution_role()\n",
    "\n",
    "\n",
    "sm_role = sagemaker.get_execution_role()\n",
    "\n",
    "aws_region = boto3.Session().region_name\n",
    "sm_session = sagemaker.Session()\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "print(f\"Using Role: {sm_role}\")\n",
    "s3_bucket = sm_session.default_bucket()\n",
    "s3_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/numenta/NAB/master/data/realKnownCause/ambient_temperature_system_failure.csv'\n",
    "df = pd.read_csv(url, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-07-04 00:00:00</td>\n",
       "      <td>69.880835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-07-04 01:00:00</td>\n",
       "      <td>71.220227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-07-04 02:00:00</td>\n",
       "      <td>70.877805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-07-04 03:00:00</td>\n",
       "      <td>68.959400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-04 04:00:00</td>\n",
       "      <td>69.283551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7262</th>\n",
       "      <td>2014-05-28 11:00:00</td>\n",
       "      <td>72.370206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7263</th>\n",
       "      <td>2014-05-28 12:00:00</td>\n",
       "      <td>72.172956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>2014-05-28 13:00:00</td>\n",
       "      <td>72.046565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>2014-05-28 14:00:00</td>\n",
       "      <td>71.825226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>2014-05-28 15:00:00</td>\n",
       "      <td>72.584089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7267 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp      value\n",
       "0     2013-07-04 00:00:00  69.880835\n",
       "1     2013-07-04 01:00:00  71.220227\n",
       "2     2013-07-04 02:00:00  70.877805\n",
       "3     2013-07-04 03:00:00  68.959400\n",
       "4     2013-07-04 04:00:00  69.283551\n",
       "...                   ...        ...\n",
       "7262  2014-05-28 11:00:00  72.370206\n",
       "7263  2014-05-28 12:00:00  72.172956\n",
       "7264  2014-05-28 13:00:00  72.046565\n",
       "7265  2014-05-28 14:00:00  71.825226\n",
       "7266  2014-05-28 15:00:00  72.584089\n",
       "\n",
       "[7267 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "#test commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['year'] = df['timestamp'].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['month'] = df['timestamp'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['day'] = df['timestamp'].apply(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['hour'] = df['timestamp'].apply(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['minute'] = df['timestamp'].apply(lambda x: x.minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-07-04 00:00:00</td>\n",
       "      <td>69.880835</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-07-04 01:00:00</td>\n",
       "      <td>71.220227</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-07-04 02:00:00</td>\n",
       "      <td>70.877805</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-07-04 03:00:00</td>\n",
       "      <td>68.959400</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-04 04:00:00</td>\n",
       "      <td>69.283551</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7262</th>\n",
       "      <td>2014-05-28 11:00:00</td>\n",
       "      <td>72.370206</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7263</th>\n",
       "      <td>2014-05-28 12:00:00</td>\n",
       "      <td>72.172956</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>2014-05-28 13:00:00</td>\n",
       "      <td>72.046565</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>2014-05-28 14:00:00</td>\n",
       "      <td>71.825226</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>2014-05-28 15:00:00</td>\n",
       "      <td>72.584089</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7267 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp      value  year  month  day  hour  minute\n",
       "0    2013-07-04 00:00:00  69.880835  2013      7    4     0       0\n",
       "1    2013-07-04 01:00:00  71.220227  2013      7    4     1       0\n",
       "2    2013-07-04 02:00:00  70.877805  2013      7    4     2       0\n",
       "3    2013-07-04 03:00:00  68.959400  2013      7    4     3       0\n",
       "4    2013-07-04 04:00:00  69.283551  2013      7    4     4       0\n",
       "...                  ...        ...   ...    ...  ...   ...     ...\n",
       "7262 2014-05-28 11:00:00  72.370206  2014      5   28    11       0\n",
       "7263 2014-05-28 12:00:00  72.172956  2014      5   28    12       0\n",
       "7264 2014-05-28 13:00:00  72.046565  2014      5   28    13       0\n",
       "7265 2014-05-28 14:00:00  71.825226  2014      5   28    14       0\n",
       "7266 2014-05-28 15:00:00  72.584089  2014      5   28    15       0\n",
       "\n",
       "[7267 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anomaly_points = [\n",
    "        [\"2013-12-10 06:25:00.000000\",\"2013-12-12 05:35:00.000000\"],\n",
    "        [\"2013-12-15 17:50:00.000000\",\"2013-12-17 17:00:00.000000\"],x\n",
    "        [\"2014-01-27 14:20:00.000000\",\"2014-01-29 13:30:00.000000\"],\n",
    "        [\"2014-02-07 14:55:00.000000\",\"2014-02-09 14:05:00.000000\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2013-12-10 06:25:00.000000', '2013-12-12 05:35:00.000000'],\n",
       " ['2013-12-15 17:50:00.000000', '2013-12-17 17:00:00.000000'],\n",
       " ['2014-01-27 14:20:00.000000', '2014-01-29 13:30:00.000000'],\n",
       " ['2014-02-07 14:55:00.000000', '2014-02-09 14:05:00.000000']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['anomaly'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-12-10 06:25:00.000000 2013-12-12 05:35:00.000000\n",
      "2013-12-15 17:50:00.000000 2013-12-17 17:00:00.000000\n",
      "2014-01-27 14:20:00.000000 2014-01-29 13:30:00.000000\n",
      "2014-02-07 14:55:00.000000 2014-02-09 14:05:00.000000\n"
     ]
    }
   ],
   "source": [
    "for start,end in anomaly_points:\n",
    "    print (start, end)\n",
    "    df.loc[  ((df['timestamp'] >= start) & (df['timestamp'] <= end)), ['anomaly']] = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 190 entries, 3420 to 4891\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   timestamp  190 non-null    datetime64[ns]\n",
      " 1   value      190 non-null    float64       \n",
      " 2   year       190 non-null    int64         \n",
      " 3   month      190 non-null    int64         \n",
      " 4   day        190 non-null    int64         \n",
      " 5   hour       190 non-null    int64         \n",
      " 6   minute     190 non-null    int64         \n",
      " 7   anomaly    190 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(6)\n",
      "memory usage: 13.4 KB\n"
     ]
    }
   ],
   "source": [
    "df[df['anomaly'] == 1].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.index = df['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(['timestamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-07-04 00:00:00</td>\n",
       "      <td>69.880835</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-07-04 01:00:00</td>\n",
       "      <td>71.220227</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-07-04 02:00:00</td>\n",
       "      <td>70.877805</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-07-04 03:00:00</td>\n",
       "      <td>68.959400</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-04 04:00:00</td>\n",
       "      <td>69.283551</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7262</th>\n",
       "      <td>2014-05-28 11:00:00</td>\n",
       "      <td>72.370206</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7263</th>\n",
       "      <td>2014-05-28 12:00:00</td>\n",
       "      <td>72.172956</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>2014-05-28 13:00:00</td>\n",
       "      <td>72.046565</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>2014-05-28 14:00:00</td>\n",
       "      <td>71.825226</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>2014-05-28 15:00:00</td>\n",
       "      <td>72.584089</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7267 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp      value  year  month  day  hour  minute  anomaly\n",
       "0    2013-07-04 00:00:00  69.880835  2013      7    4     0       0        0\n",
       "1    2013-07-04 01:00:00  71.220227  2013      7    4     1       0        0\n",
       "2    2013-07-04 02:00:00  70.877805  2013      7    4     2       0        0\n",
       "3    2013-07-04 03:00:00  68.959400  2013      7    4     3       0        0\n",
       "4    2013-07-04 04:00:00  69.283551  2013      7    4     4       0        0\n",
       "...                  ...        ...   ...    ...  ...   ...     ...      ...\n",
       "7262 2014-05-28 11:00:00  72.370206  2014      5   28    11       0        0\n",
       "7263 2014-05-28 12:00:00  72.172956  2014      5   28    12       0        0\n",
       "7264 2014-05-28 13:00:00  72.046565  2014      5   28    13       0        0\n",
       "7265 2014-05-28 14:00:00  71.825226  2014      5   28    14       0        0\n",
       "7266 2014-05-28 15:00:00  72.584089  2014      5   28    15       0        0\n",
       "\n",
       "[7267 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !conda install -y holoviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'holoviews'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mholoviews\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhv\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mholoviews\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m opts\n\u001b[1;32m      4\u001b[0m hv\u001b[38;5;241m.\u001b[39mextension(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbokeh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'holoviews'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import RandomCutForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prefix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s3_bucket, \u001b[43mprefix\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prefix' is not defined"
     ]
    }
   ],
   "source": [
    "s3_bucket, prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "prefix='randomcut'\n",
    "rcf = RandomCutForest(role=sm_role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='ml.m4.xlarge',\n",
    "                      data_location=f's3://{s3_bucket}/{prefix}/',\n",
    "                      output_path=f's3://{s3_bucket}/{prefix}/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: randomcutforest-2023-12-08-05-33-50-347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-08 05:33:50 Starting - Starting the training job......\n",
      "2023-12-08 05:34:26 Starting - Preparing the instances for training......\n",
      "2023-12-08 05:35:51 Downloading - Downloading input data...\n",
      "2023-12-08 05:36:21 Training - Downloading the training image..................\n",
      "2023-12-08 05:39:07 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/scipy/optimize/_shgo.py:495: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if cons['type'] is 'ineq':\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/scipy/optimize/_shgo.py:743: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if len(self.X_min) is not 0:\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-conf.json: {'num_samples_per_tree': 256, 'num_trees': 100, 'force_dense': 'true', 'eval_metrics': ['accuracy', 'precision_recall_fscore'], 'epochs': 1, 'mini_batch_size': 1000, '_log_level': 'info', '_kvstore': 'dist_async', '_num_kv_servers': 'auto', '_num_gpus': 'auto', '_tuning_objective_metric': '', '_ftp_port': 8999}\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '1', 'mini_batch_size': '1000'}\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Final configuration: {'num_samples_per_tree': 256, 'num_trees': 100, 'force_dense': 'true', 'eval_metrics': ['accuracy', 'precision_recall_fscore'], 'epochs': 1, 'mini_batch_size': '1000', '_log_level': 'info', '_kvstore': 'dist_async', '_num_kv_servers': 'auto', '_num_gpus': 'auto', '_tuning_objective_metric': '', '_ftp_port': 8999, 'feature_dim': '1'}\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 WARNING 139853672802112] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-108-255.ec2.internal', 'TRAINING_JOB_NAME': 'randomcutforest-2023-12-08-05-33-50-347', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:287758680514:training-job/randomcutforest-2023-12-08-05-33-50-347', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-970feb89692704670c87a0857ef4546edeb49289311c14209f7ca0c23c73028c-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.8/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'SAGEMAKER_MANAGED_WARMPOOL_CACHE_DIRECTORY': '/opt/ml/sagemaker/warmpoolcache', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-east-1', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'CUDA_VERSION': '11.1', 'HOME': '/root', 'SHLVL': '1', 'CUDA_COMPAT_NDRIVER_SUPPORTED_VERSION': '455.32.00', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE'}\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] envs={'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-108-255.ec2.internal', 'TRAINING_JOB_NAME': 'randomcutforest-2023-12-08-05-33-50-347', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:287758680514:training-job/randomcutforest-2023-12-08-05-33-50-347', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-970feb89692704670c87a0857ef4546edeb49289311c14209f7ca0c23c73028c-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.8/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'SAGEMAKER_MANAGED_WARMPOOL_CACHE_DIRECTORY': '/opt/ml/sagemaker/warmpoolcache', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-east-1', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'CUDA_VERSION': '11.1', 'HOME': '/root', 'SHLVL': '1', 'CUDA_COMPAT_NDRIVER_SUPPORTED_VERSION': '455.32.00', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE', 'DMLC_ROLE': 'scheduler', 'DMLC_PS_ROOT_URI': '10.0.108.255', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-108-255.ec2.internal', 'TRAINING_JOB_NAME': 'randomcutforest-2023-12-08-05-33-50-347', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:287758680514:training-job/randomcutforest-2023-12-08-05-33-50-347', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-970feb89692704670c87a0857ef4546edeb49289311c14209f7ca0c23c73028c-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.8/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'SAGEMAKER_MANAGED_WARMPOOL_CACHE_DIRECTORY': '/opt/ml/sagemaker/warmpoolcache', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-east-1', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'CUDA_VERSION': '11.1', 'HOME': '/root', 'SHLVL': '1', 'CUDA_COMPAT_NDRIVER_SUPPORTED_VERSION': '455.32.00', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE'}\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] envs={'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-108-255.ec2.internal', 'TRAINING_JOB_NAME': 'randomcutforest-2023-12-08-05-33-50-347', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:287758680514:training-job/randomcutforest-2023-12-08-05-33-50-347', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-970feb89692704670c87a0857ef4546edeb49289311c14209f7ca0c23c73028c-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.8/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'SAGEMAKER_MANAGED_WARMPOOL_CACHE_DIRECTORY': '/opt/ml/sagemaker/warmpoolcache', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-east-1', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'CUDA_VERSION': '11.1', 'HOME': '/root', 'SHLVL': '1', 'CUDA_COMPAT_NDRIVER_SUPPORTED_VERSION': '455.32.00', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE', 'DMLC_ROLE': 'server', 'DMLC_PS_ROOT_URI': '10.0.108.255', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Environment: {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-108-255.ec2.internal', 'TRAINING_JOB_NAME': 'randomcutforest-2023-12-08-05-33-50-347', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:287758680514:training-job/randomcutforest-2023-12-08-05-33-50-347', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-970feb89692704670c87a0857ef4546edeb49289311c14209f7ca0c23c73028c-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.8/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'SAGEMAKER_MANAGED_WARMPOOL_CACHE_DIRECTORY': '/opt/ml/sagemaker/warmpoolcache', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-east-1', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'CUDA_VERSION': '11.1', 'HOME': '/root', 'SHLVL': '1', 'CUDA_COMPAT_NDRIVER_SUPPORTED_VERSION': '455.32.00', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE', 'DMLC_ROLE': 'worker', 'DMLC_PS_ROOT_URI': '10.0.108.255', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34mProcess 34 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 43 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Using default worker.\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Verifying hyperparamemters...\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Hyperparameters are correct.\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Validating that feature_dim agrees with dimensions in training data...\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] feature_dim is correct.\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Validating memory limits...\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Available memory in bytes: 15411896320\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Estimated sample size in bytes: 409600\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Estimated memory needed to build the forest in bytes: 1024000\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Memory limits validated.\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Starting cluster sharing facilities...\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139850846041856] concurrency model: async\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139853672802112] Create Store: dist_async\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139850846041856] masquerade (NAT) address: None\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139850846041856] passive ports: None\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:31 INFO 139850846041856] >>> starting FTP server on 0.0.0.0:8999, pid=7 <<<\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] Cluster sharing facilities started.\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] Verifying all workers are accessible...\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] All workers accessible.\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] Initializing Sampler...\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] Sampler correctly initialized.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702013971.2740595, \"EndTime\": 1702013972.5895967, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 1312.7410411834717, \"count\": 1, \"min\": 1312.7410411834717, \"max\": 1312.7410411834717}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702013972.5898118, \"EndTime\": 1702013972.5898485, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[2023-12-08 05:39:32.590] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 1315, \"num_examples\": 1, \"num_bytes\": 32000}\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] Sampling training data...\u001b[0m\n",
      "\u001b[34m[2023-12-08 05:39:32.608] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 17, \"num_examples\": 8, \"num_bytes\": 232544}\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] Sampling training data completed.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702013972.5897439, \"EndTime\": 1702013972.6105359, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"update.time\": {\"sum\": 20.288467407226562, \"count\": 1, \"min\": 20.288467407226562, \"max\": 20.288467407226562}}}\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702013972.590205, \"EndTime\": 1702013972.6112297, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7267.0, \"count\": 1, \"min\": 7267, \"max\": 7267}, \"Total Batches Seen\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Max Records Seen Between Resets\": {\"sum\": 7267.0, \"count\": 1, \"min\": 7267, \"max\": 7267}, \"Max Batches Seen Between Resets\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 7267.0, \"count\": 1, \"min\": 7267, \"max\": 7267}, \"Number of Batches Since Last Reset\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}}}\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] #throughput_metric: host=algo-1, train throughput=342060.7490769524 records/second\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] Master node: building Random Cut Forest...\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] Gathering samples...\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] 7267 samples gathered\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] Building Random Cut Forest...\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] Random Cut Forest built: \u001b[0m\n",
      "\u001b[34mForestInfo{num_trees: 100, num_samples_in_forest: 7200, num_samples_per_tree: 72, sample_dim: 1, shingle_size: 1, trees_num_nodes: [143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, ], trees_depth: [13, 12, 12, 13, 13, 15, 11, 15, 14, 14, 11, 14, 13, 16, 12, 12, 15, 14, 13, 14, 15, 12, 11, 14, 14, 13, 12, 13, 18, 14, 13, 13, 15, 14, 12, 12, 15, 13, 12, 13, 13, 15, 12, 11, 13, 13, 14, 13, 17, 12, 14, 16, 20, 16, 13, 12, 17, 12, 20, 14, 19, 16, 12, 12, 15, 12, 12, 15, 11, 14, 16, 15, 12, 14, 11, 13, 13, 12, 15, 13, 12, 12, 15, 11, 15, 13, 17, 14, 14, 14, 13, 12, 13, 16, 13, 14, 16, 14, 11, 11, ], max_num_nodes: 143, min_num_nodes: 143, avg_num_nodes: 143, max_tree_depth: 20, min_tree_depth: 11, avg_tree_depth: 13, mem_size: 1488048}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702013972.610702, \"EndTime\": 1702013972.6236968, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"fit_model.time\": {\"sum\": 5.827426910400391, \"count\": 1, \"min\": 5.827426910400391, \"max\": 5.827426910400391}, \"model.bytes\": {\"sum\": 1488048.0, \"count\": 1, \"min\": 1488048, \"max\": 1488048}, \"finalize.time\": {\"sum\": 11.844873428344727, \"count\": 1, \"min\": 11.844873428344727, \"max\": 11.844873428344727}}}\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] Master node: Serializing the RandomCutForest model\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702013972.6238108, \"EndTime\": 1702013972.6447122, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"serialize_model.time\": {\"sum\": 20.83730697631836, \"count\": 1, \"min\": 20.83730697631836, \"max\": 20.83730697631836}}}\u001b[0m\n",
      "\u001b[34m[12/08/2023 05:39:32 INFO 139853672802112] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702013972.6448236, \"EndTime\": 1702013972.647003, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 26.46660804748535, \"count\": 1, \"min\": 26.46660804748535, \"max\": 26.46660804748535}, \"totaltime\": {\"sum\": 1406.543493270874, \"count\": 1, \"min\": 1406.543493270874, \"max\": 1406.543493270874}}}\u001b[0m\n",
      "\n",
      "2023-12-08 05:39:53 Uploading - Uploading generated training model\n",
      "2023-12-08 05:39:53 Completed - Training job completed\n",
      "Training seconds: 242\n",
      "Billable seconds: 242\n"
     ]
    }
   ],
   "source": [
    "rcf.fit(rcf.record_set(df['value'].to_numpy().reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (1293824993.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[34], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    rcf_interference = rcf.deploy(initial_instance_count=1, ins)\u001b[0m\n\u001b[0m                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "rcf_interference = rcf.deploy(initial_instance_count=1, ins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serverless import ServerlessInferenceConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=2048,\n",
    "    max_concurrency=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating model with name: randomcutforest-2023-12-08-05-56-39-318\n",
      "INFO:sagemaker:Creating endpoint-config with name randomcutforest-2023-12-08-05-56-39-318\n",
      "INFO:sagemaker:Creating endpoint with name randomcutforest-2023-12-08-05-56-39-318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.amazon.randomcutforest.RandomCutForestPredictor at 0x7fdbc2fb7d30>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcf.deploy(initial_instance_count=1, serverless_inference_config=serverless_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['randomcutforest-2023-12-08-05-56-39-318']\n"
     ]
    }
   ],
   "source": [
    "def list_predictors():\n",
    "    # Initialize an empty list to store the names of predictors\n",
    "    predictor_names = []\n",
    "\n",
    "    # Using the paginator to handle the case where there are more predictors than can be returned in a single API call\n",
    "    paginator = sm_client.get_paginator('list_endpoints')\n",
    "\n",
    "    # Iterate over the pages of results\n",
    "    for page in paginator.paginate():\n",
    "        # Extract the endpoint names from the current page and add them to the list\n",
    "        for endpoint in page['Endpoints']:\n",
    "            predictor_names.append(endpoint['EndpointName'])\n",
    "\n",
    "    return predictor_names\n",
    "\n",
    "# Call the function and print the list of predictor names\n",
    "predictor_names = list_predictors()\n",
    "print(predictor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "machine_data_numpy = df.value.to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69.88083514],\n",
       "       [71.22022706],\n",
       "       [70.87780496],\n",
       "       [68.95939994],\n",
       "       [69.28355102],\n",
       "       [70.06096581]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_data_numpy[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = Predictor(endpoint_name='randomcutforest-2023-12-08-05-56-39-318')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModelNotReadyException",
     "evalue": "An error occurred (ModelNotReadyException) when calling the InvokeEndpoint operation (reached max retries: 4): Model for endpoint randomcutforest-2023-12-08-05-56-39-318 variant AllTraffic is not ready for inference yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelNotReadyException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m predictor\u001b[38;5;241m.\u001b[39mdeserializer \u001b[38;5;241m=\u001b[39m JSONDeserializer()\n\u001b[1;32m      5\u001b[0m machine_data_numpy \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmachine_data_numpy\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mContentType\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext/csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAccept\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/base_predictor.py:206\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id, custom_attributes, component_name)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference_component_name:\n\u001b[1;32m    204\u001b[0m     request_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceComponentName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inference_component_name\n\u001b[0;32m--> 206\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:553\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m     )\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:1009\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1007\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mModelNotReadyException\u001b[0m: An error occurred (ModelNotReadyException) when calling the InvokeEndpoint operation (reached max retries: 4): Model for endpoint randomcutforest-2023-12-08-05-56-39-318 variant AllTraffic is not ready for inference yet."
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "predictor.serializer = CSVSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "machine_data_numpy = df.value.to_numpy().reshape(-1, 1)\n",
    "\n",
    "results = predictor.predict(\n",
    "    machine_data_numpy[:6], initial_args={\"ContentType\": \"text/csv\", \"Accept\": \"application/json\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction using invoke_endpoint not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the SageMaker Runtime client\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example data to be predicted\n",
    "data = {\"features\": [5.1, 3.5, 1.4, 0.2]}\n",
    "serialized_data = json.dumps(machine_data_numpy[:6].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from model with message \"unable to evaluate payload provided\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/randomcutforest-2023-12-08-05-56-39-318 in account 287758680514 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Invoke the endpoint\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43msagemaker_runtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEndpointName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandomcutforest-2023-12-08-05-56-39-318\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mContentType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext/csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mAccept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mBody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserialized_data\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:553\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m     )\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:1009\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1007\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from model with message \"unable to evaluate payload provided\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/randomcutforest-2023-12-08-05-56-39-318 in account 287758680514 for more information."
     ]
    }
   ],
   "source": [
    "\n",
    "# Invoke the endpoint\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName='randomcutforest-2023-12-08-05-56-39-318',\n",
    "    ContentType='text/csv',\n",
    "    Accept= 'application/json',\n",
    "    Body=serialized_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[69.88083514], [71.22022706], [70.87780496], [68.95939994], [69.28355102], [70.06096581]]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serialized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type ndarray is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmachine_data_numpy\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type ndarray is not JSON serializable"
     ]
    }
   ],
   "source": [
    "json.dumps(machine_data_numpy[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2013-07-04 00:00:00    69.880835\n",
       "2013-07-04 01:00:00    71.220227\n",
       "2013-07-04 02:00:00    70.877805\n",
       "2013-07-04 03:00:00    68.959400\n",
       "2013-07-04 04:00:00    69.283551\n",
       "                         ...    \n",
       "2014-05-28 11:00:00    72.370206\n",
       "2014-05-28 12:00:00    72.172956\n",
       "2014-05-28 13:00:00    72.046565\n",
       "2014-05-28 14:00:00    71.825226\n",
       "2014-05-28 15:00:00    72.584089\n",
       "Name: value, Length: 7267, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-example-files-prod-us-east-1'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region=boto3.Session().region_name\n",
    "\n",
    "downloaded_data_prefix = \"datasets/tabular/anomaly_benchmark_taxi\"\n",
    "data_filename = \"NAB_nyc_taxi.csv\"\n",
    "downloaded_data_bucket = f\"sagemaker-example-files-prod-{region}\"\n",
    "downloaded_data_prefix = \"datasets/tabular/anomaly_benchmark_taxi\"\n",
    "\n",
    "data_filename = \"NAB_nyc_taxi.csv\"\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(downloaded_data_bucket, f\"{downloaded_data_prefix}/{data_filename}\", data_filename)\n",
    "taxi_data = pd.read_csv(data_filename, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-01 00:00:00</td>\n",
       "      <td>10844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-01 00:30:00</td>\n",
       "      <td>8127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-01 01:00:00</td>\n",
       "      <td>6210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-01 01:30:00</td>\n",
       "      <td>4656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-07-01 02:00:00</td>\n",
       "      <td>3820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10315</th>\n",
       "      <td>2015-01-31 21:30:00</td>\n",
       "      <td>24670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10316</th>\n",
       "      <td>2015-01-31 22:00:00</td>\n",
       "      <td>25721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10317</th>\n",
       "      <td>2015-01-31 22:30:00</td>\n",
       "      <td>27309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10318</th>\n",
       "      <td>2015-01-31 23:00:00</td>\n",
       "      <td>26591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10319</th>\n",
       "      <td>2015-01-31 23:30:00</td>\n",
       "      <td>26288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10320 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp  value\n",
       "0      2014-07-01 00:00:00  10844\n",
       "1      2014-07-01 00:30:00   8127\n",
       "2      2014-07-01 01:00:00   6210\n",
       "3      2014-07-01 01:30:00   4656\n",
       "4      2014-07-01 02:00:00   3820\n",
       "...                    ...    ...\n",
       "10315  2015-01-31 21:30:00  24670\n",
       "10316  2015-01-31 22:00:00  25721\n",
       "10317  2015-01-31 22:30:00  27309\n",
       "10318  2015-01-31 23:00:00  26591\n",
       "10319  2015-01-31 23:30:00  26288\n",
       "\n",
       "[10320 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10844, 8127, 6210, ..., 27309, 26591, 26288], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.values[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def shingle(data, shingle_size):\n",
    "    num_data = len(data)\n",
    "    shingled_data = np.zeros((num_data - shingle_size, shingle_size))\n",
    "\n",
    "    for n in range(num_data - shingle_size):\n",
    "        shingled_data[n] = data[n : (n + shingle_size)]\n",
    "    return shingled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10844.  8127.  6210. ... 21733. 20104. 16111.]\n",
      " [ 8127.  6210.  4656. ... 20104. 16111. 13370.]\n",
      " [ 6210.  4656.  3820. ... 16111. 13370.  9945.]\n",
      " ...\n",
      " [26874. 26928. 26000. ... 23719. 24670. 25721.]\n",
      " [26928. 26000. 25778. ... 24670. 25721. 27309.]\n",
      " [26000. 25778. 23304. ... 25721. 27309. 26591.]]\n"
     ]
    }
   ],
   "source": [
    "shingle_size = 48\n",
    "\n",
    "taxi_data_shingled = shingle(taxi_data.values[:, 1], shingle_size)\n",
    "print(taxi_data_shingled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10272, 48)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data_shingled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2257b1c3513dc4782645ad49f694a4b0012bebbbbc3534a56d350db8e4f89a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
